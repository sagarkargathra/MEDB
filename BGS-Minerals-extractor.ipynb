{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cc14858-8176-4917-ad23-9a6751ce539a",
   "metadata": {},
   "source": [
    "## Environment Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff1b2550-0626-4d57-8917-51d444cde7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vegeta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install requests pandas openpyxl\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sqlite3\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0ec31-3548-4d0f-844a-419fac01c282",
   "metadata": {},
   "source": [
    "## BGS API Connection Discovery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a11049-a9dd-4a94-aacb-d0f7cffe7fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Connection Successful!\n",
      "\n",
      "Total columns found: 22\n",
      "Column Names: ['country_trans', 'bgs_sub_commodity_trans', 'concat_table_notes_code', 'country_iso2_code', 'erml_group', 'concat_table_notes_text', 'year', 'country_iso3_code', 'erml_commodity', 'concat_figure_notes_code', 'pole_of_inaccessibility_longitude', 'erml_sub_commodity', 'concat_figure_notes_text', 'pole_of_inaccessibility_latitude', 'cgi_commodity_url', 'yearbook_table_id', 'quantity', 'yearbook_table_trans', 'bgs_commodity_code', 'units', 'bgs_statistic_type_trans', 'bgs_commodity_trans']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_trans</th>\n",
       "      <th>bgs_sub_commodity_trans</th>\n",
       "      <th>concat_table_notes_code</th>\n",
       "      <th>country_iso2_code</th>\n",
       "      <th>erml_group</th>\n",
       "      <th>concat_table_notes_text</th>\n",
       "      <th>year</th>\n",
       "      <th>country_iso3_code</th>\n",
       "      <th>erml_commodity</th>\n",
       "      <th>concat_figure_notes_code</th>\n",
       "      <th>...</th>\n",
       "      <th>concat_figure_notes_text</th>\n",
       "      <th>pole_of_inaccessibility_latitude</th>\n",
       "      <th>cgi_commodity_url</th>\n",
       "      <th>yearbook_table_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>yearbook_table_trans</th>\n",
       "      <th>bgs_commodity_code</th>\n",
       "      <th>units</th>\n",
       "      <th>bgs_statistic_type_trans</th>\n",
       "      <th>bgs_commodity_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BF</td>\n",
       "      <td>Silver</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-01-01T00:00:00</td>\n",
       "      <td>BFA</td>\n",
       "      <td>Silver (mine production, metal content)</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>12.591396</td>\n",
       "      <td>http://resource.geosciml.org/classifier/cgi/co...</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mine production of silver</td>\n",
       "      <td>1995</td>\n",
       "      <td>kilograms (metal content)</td>\n",
       "      <td>Production</td>\n",
       "      <td>silver, mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BF</td>\n",
       "      <td>Silver</td>\n",
       "      <td>None</td>\n",
       "      <td>2007-01-01T00:00:00</td>\n",
       "      <td>BFA</td>\n",
       "      <td>Silver (mine production, metal content)</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>12.591396</td>\n",
       "      <td>http://resource.geosciml.org/classifier/cgi/co...</td>\n",
       "      <td>128</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Mine production of silver</td>\n",
       "      <td>1995</td>\n",
       "      <td>kilograms (metal content)</td>\n",
       "      <td>Production</td>\n",
       "      <td>silver, mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BF</td>\n",
       "      <td>Silver</td>\n",
       "      <td>None</td>\n",
       "      <td>2008-01-01T00:00:00</td>\n",
       "      <td>BFA</td>\n",
       "      <td>Silver (mine production, metal content)</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>12.591396</td>\n",
       "      <td>http://resource.geosciml.org/classifier/cgi/co...</td>\n",
       "      <td>128</td>\n",
       "      <td>800.0</td>\n",
       "      <td>Mine production of silver</td>\n",
       "      <td>1995</td>\n",
       "      <td>kilograms (metal content)</td>\n",
       "      <td>Production</td>\n",
       "      <td>silver, mine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_trans bgs_sub_commodity_trans concat_table_notes_code  \\\n",
       "0  Burkina Faso                    None                    None   \n",
       "1  Burkina Faso                    None                    None   \n",
       "2  Burkina Faso                    None                    None   \n",
       "\n",
       "  country_iso2_code erml_group concat_table_notes_text                 year  \\\n",
       "0                BF     Silver                    None  2006-01-01T00:00:00   \n",
       "1                BF     Silver                    None  2007-01-01T00:00:00   \n",
       "2                BF     Silver                    None  2008-01-01T00:00:00   \n",
       "\n",
       "  country_iso3_code                           erml_commodity  \\\n",
       "0               BFA  Silver (mine production, metal content)   \n",
       "1               BFA  Silver (mine production, metal content)   \n",
       "2               BFA  Silver (mine production, metal content)   \n",
       "\n",
       "  concat_figure_notes_code  ...  concat_figure_notes_text  \\\n",
       "0                     None  ...                      None   \n",
       "1                     None  ...                      None   \n",
       "2                     None  ...                      None   \n",
       "\n",
       "  pole_of_inaccessibility_latitude  \\\n",
       "0                        12.591396   \n",
       "1                        12.591396   \n",
       "2                        12.591396   \n",
       "\n",
       "                                   cgi_commodity_url  yearbook_table_id  \\\n",
       "0  http://resource.geosciml.org/classifier/cgi/co...                128   \n",
       "1  http://resource.geosciml.org/classifier/cgi/co...                128   \n",
       "2  http://resource.geosciml.org/classifier/cgi/co...                128   \n",
       "\n",
       "  quantity       yearbook_table_trans  bgs_commodity_code  \\\n",
       "0      0.0  Mine production of silver                1995   \n",
       "1    100.0  Mine production of silver                1995   \n",
       "2    800.0  Mine production of silver                1995   \n",
       "\n",
       "                       units  bgs_statistic_type_trans bgs_commodity_trans  \n",
       "0  kilograms (metal content)                Production        silver, mine  \n",
       "1  kilograms (metal content)                Production        silver, mine  \n",
       "2  kilograms (metal content)                Production        silver, mine  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discovery_url = \"https://ogcapi.bgs.ac.uk/collections/world-mineral-statistics/items?limit=5\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(discovery_url)\n",
    "    response.raise_for_status() # This will catch if the website is down\n",
    "    \n",
    "    data = response.json()\n",
    "    # In OGC APIs, the data is inside 'features', and the actual columns are in 'properties'\n",
    "    sample_data = [f['properties'] for f in data['features']]\n",
    "    discovery_df = pd.DataFrame(sample_data)\n",
    "    \n",
    "    print(\"‚úÖ API Connection Successful!\")\n",
    "    print(f\"\\nTotal columns found: {len(discovery_df.columns)}\")\n",
    "    print(f\"Column Names: {discovery_df.columns.tolist()}\")\n",
    "    \n",
    "    # Show the data\n",
    "    display(discovery_df.head(3))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e2944-e1ac-4588-a5b8-70aeab93d18a",
   "metadata": {},
   "source": [
    "## Scanning Databade for number of Minerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "734dc6df-a4b9-4122-81b9-9486b82e50ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting full database scan... mapping every mineral name.\n",
      "Checking records 0 to 10000...\n",
      "Checking records 10000 to 20000...\n",
      "Checking records 20000 to 30000...\n",
      "Checking records 30000 to 40000...\n",
      "Checking records 40000 to 50000...\n",
      "Checking records 50000 to 60000...\n",
      "Checking records 60000 to 70000...\n",
      "Checking records 70000 to 80000...\n",
      "Checking records 80000 to 90000...\n",
      "Checking records 90000 to 100000...\n",
      "Checking records 100000 to 110000...\n",
      "Checking records 110000 to 120000...\n",
      "Checking records 120000 to 130000...\n",
      "Checking records 130000 to 140000...\n",
      "Checking records 140000 to 150000...\n",
      "Checking records 150000 to 160000...\n",
      "Checking records 160000 to 170000...\n",
      "Checking records 170000 to 180000...\n",
      "Checking records 180000 to 190000...\n",
      "Checking records 190000 to 200000...\n",
      "Checking records 200000 to 210000...\n",
      "Checking records 210000 to 220000...\n",
      "Checking records 220000 to 230000...\n",
      "Checking records 230000 to 240000...\n",
      "Checking records 240000 to 250000...\n",
      "Checking records 250000 to 260000...\n",
      "Checking records 260000 to 270000...\n",
      "Checking records 270000 to 280000...\n",
      "Checking records 280000 to 290000...\n",
      "Checking records 290000 to 300000...\n",
      "Checking records 300000 to 310000...\n",
      "Checking records 310000 to 320000...\n",
      "Checking records 320000 to 330000...\n",
      "Checking records 330000 to 340000...\n",
      "Checking records 340000 to 350000...\n",
      "Checking records 350000 to 360000...\n",
      "Checking records 360000 to 370000...\n",
      "Checking records 370000 to 380000...\n",
      "Checking records 380000 to 390000...\n",
      "Checking records 390000 to 400000...\n",
      "Checking records 400000 to 408480...\n",
      "\n",
      "‚úÖ SCAN COMPLETE!\n",
      "Found 61 unique Mineral Groups.\n",
      "------------------------------\n",
      "['Aggregates and related materials', 'Antimony', 'Arsenic', 'Asbestos', 'Barytes', 'Bauxite, alumina and aluminium', \"Bentonite and fuller's earth\", 'Beryllium', 'Bismuth', 'Borates', 'Bromine', 'Cadmium', 'Cement', 'Chromium', 'Cobalt', 'Copper', 'Diamond', 'Diatomite', 'Feldspar', 'Fluorspar', 'Gallium', 'Germanium', 'Gold', 'Graphite', 'Gypsum', 'Indium', 'Iodine', 'Iron and steel', 'Kaolin', 'Lead', 'Lithium', 'Magnesite', 'Magnesium', 'Manganese', 'Mercury', 'Mica', 'Molybdenum', 'Nepheline syenite', 'Nickel', 'Perlite', 'Phosphate rock', 'Platinum group metals', 'Potash', 'Rare earths', 'Rhenium', 'Salt', 'Selenium', 'Sillimanite and related minerals', 'Silver', 'Strontium', 'Talc', 'Tantalum and niobium', 'Tellurium', 'Tin', 'Titanium', 'Tungsten', 'Vanadium', 'Vermiculite', 'Wollastonite', 'Zinc', 'Zirconium']\n"
     ]
    }
   ],
   "source": [
    "# This flips through every \"page\" of the BGS database\n",
    "base_url = \"https://ogcapi.bgs.ac.uk/collections/world-mineral-statistics/items\"\n",
    "all_minerals = set()\n",
    "offset = 0\n",
    "limit = 10000 \n",
    "\n",
    "print(\"üöÄ Starting full database scan... mapping every mineral name.\")\n",
    "\n",
    "while True:\n",
    "    params = {'f': 'json', 'limit': limit, 'offset': offset}\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            break\n",
    "            \n",
    "        data = response.json()\n",
    "        features = data.get('features', [])\n",
    "        \n",
    "        if not features:\n",
    "            break  # We reached the end of the database\n",
    "            \n",
    "        # Add every mineral name found in this batch to our set\n",
    "        for f in features:\n",
    "            name = f['properties'].get('erml_group')\n",
    "            if name:\n",
    "                all_minerals.add(name)\n",
    "        \n",
    "        print(f\"Checking records {offset} to {offset + len(features)}...\")\n",
    "        offset += limit\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Connection interrupted: {e}\")\n",
    "        break\n",
    "\n",
    "# Sort them alphabetically for a clean presentation\n",
    "final_list = sorted(list(all_minerals))\n",
    "\n",
    "print(\"\\n‚úÖ SCAN COMPLETE!\")\n",
    "print(f\"Found {len(final_list)} unique Mineral Groups.\")\n",
    "print(\"-\" * 30)\n",
    "print(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ed798-fff7-4be8-b2d9-5dd8129d9a82",
   "metadata": {},
   "source": [
    "## Master ETL (Extract, Transform, Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddff007d-f34c-493a-a3b2-6189a10168d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Starting Master Harvest...\n",
      "‚úÖ Secured 5000 / 408480 rows...\n",
      "‚úÖ Secured 10000 / 408480 rows...\n",
      "‚úÖ Secured 15000 / 408480 rows...\n",
      "‚úÖ Secured 20000 / 408480 rows...\n",
      "‚úÖ Secured 25000 / 408480 rows...\n",
      "‚úÖ Secured 30000 / 408480 rows...\n",
      "‚úÖ Secured 35000 / 408480 rows...\n",
      "‚úÖ Secured 40000 / 408480 rows...\n",
      "‚úÖ Secured 45000 / 408480 rows...\n",
      "‚úÖ Secured 50000 / 408480 rows...\n",
      "‚úÖ Secured 55000 / 408480 rows...\n",
      "‚úÖ Secured 60000 / 408480 rows...\n",
      "‚úÖ Secured 65000 / 408480 rows...\n",
      "‚úÖ Secured 70000 / 408480 rows...\n",
      "‚úÖ Secured 75000 / 408480 rows...\n",
      "‚úÖ Secured 80000 / 408480 rows...\n",
      "‚úÖ Secured 85000 / 408480 rows...\n",
      "‚úÖ Secured 90000 / 408480 rows...\n",
      "‚úÖ Secured 95000 / 408480 rows...\n",
      "‚úÖ Secured 100000 / 408480 rows...\n",
      "‚úÖ Secured 105000 / 408480 rows...\n",
      "‚úÖ Secured 110000 / 408480 rows...\n",
      "‚úÖ Secured 115000 / 408480 rows...\n",
      "‚úÖ Secured 120000 / 408480 rows...\n",
      "‚úÖ Secured 125000 / 408480 rows...\n",
      "‚úÖ Secured 130000 / 408480 rows...\n",
      "‚úÖ Secured 135000 / 408480 rows...\n",
      "‚úÖ Secured 140000 / 408480 rows...\n",
      "‚úÖ Secured 145000 / 408480 rows...\n",
      "‚úÖ Secured 150000 / 408480 rows...\n",
      "‚úÖ Secured 155000 / 408480 rows...\n",
      "‚úÖ Secured 160000 / 408480 rows...\n",
      "‚úÖ Secured 165000 / 408480 rows...\n",
      "‚úÖ Secured 170000 / 408480 rows...\n",
      "‚úÖ Secured 175000 / 408480 rows...\n",
      "‚úÖ Secured 180000 / 408480 rows...\n",
      "‚úÖ Secured 185000 / 408480 rows...\n",
      "‚úÖ Secured 190000 / 408480 rows...\n",
      "‚úÖ Secured 195000 / 408480 rows...\n",
      "‚úÖ Secured 200000 / 408480 rows...\n",
      "‚úÖ Secured 205000 / 408480 rows...\n",
      "‚úÖ Secured 210000 / 408480 rows...\n",
      "‚úÖ Secured 215000 / 408480 rows...\n",
      "‚úÖ Secured 220000 / 408480 rows...\n",
      "‚úÖ Secured 225000 / 408480 rows...\n",
      "‚úÖ Secured 230000 / 408480 rows...\n",
      "‚úÖ Secured 235000 / 408480 rows...\n",
      "‚úÖ Secured 240000 / 408480 rows...\n",
      "‚úÖ Secured 245000 / 408480 rows...\n",
      "‚úÖ Secured 250000 / 408480 rows...\n",
      "‚úÖ Secured 255000 / 408480 rows...\n",
      "‚úÖ Secured 260000 / 408480 rows...\n",
      "‚úÖ Secured 265000 / 408480 rows...\n",
      "‚úÖ Secured 270000 / 408480 rows...\n",
      "‚úÖ Secured 275000 / 408480 rows...\n",
      "‚úÖ Secured 280000 / 408480 rows...\n",
      "‚úÖ Secured 285000 / 408480 rows...\n",
      "‚úÖ Secured 290000 / 408480 rows...\n",
      "‚úÖ Secured 295000 / 408480 rows...\n",
      "‚úÖ Secured 300000 / 408480 rows...\n",
      "‚úÖ Secured 305000 / 408480 rows...\n",
      "‚úÖ Secured 310000 / 408480 rows...\n",
      "‚úÖ Secured 315000 / 408480 rows...\n",
      "‚úÖ Secured 320000 / 408480 rows...\n",
      "‚úÖ Secured 325000 / 408480 rows...\n",
      "‚úÖ Secured 330000 / 408480 rows...\n",
      "‚úÖ Secured 335000 / 408480 rows...\n",
      "‚úÖ Secured 340000 / 408480 rows...\n",
      "‚úÖ Secured 345000 / 408480 rows...\n",
      "‚úÖ Secured 350000 / 408480 rows...\n",
      "‚úÖ Secured 355000 / 408480 rows...\n",
      "‚úÖ Secured 360000 / 408480 rows...\n",
      "‚úÖ Secured 365000 / 408480 rows...\n",
      "‚úÖ Secured 370000 / 408480 rows...\n",
      "‚úÖ Secured 375000 / 408480 rows...\n",
      "‚úÖ Secured 380000 / 408480 rows...\n",
      "‚úÖ Secured 385000 / 408480 rows...\n",
      "‚úÖ Secured 390000 / 408480 rows...\n",
      "‚úÖ Secured 395000 / 408480 rows...\n",
      "‚úÖ Secured 400000 / 408480 rows...\n",
      "‚úÖ Secured 405000 / 408480 rows...\n",
      "‚ö†Ô∏è Error at row 405000: table FullMineralData has no column named shape\n",
      "‚ö° Creating high-speed indexes...\n",
      "üéä FINISHED! Your master tool is ready.\n"
     ]
    }
   ],
   "source": [
    "def build_master_database():\n",
    "    db_name = \"BGS_Full_Archive_Master.db\"\n",
    "    base_url = \"https://ogcapi.bgs.ac.uk/collections/world-mineral-statistics/items\"\n",
    "    \n",
    "    # Connect to the database file\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    offset = 0\n",
    "    limit = 5000 \n",
    "    total_expected = 408480\n",
    "    \n",
    "    print(f\"üì¶ Starting Master Harvest...\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            params = {'f': 'json', 'limit': limit, 'offset': offset}\n",
    "            # We already imported 'requests' in Block 1, so we just use it!\n",
    "            response = requests.get(base_url, params=params, timeout=60)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"‚ö†Ô∏è Server Busy (Status {response.status_code}). Retrying in 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "\n",
    "            data = response.json()\n",
    "            features = data.get('features', [])\n",
    "            \n",
    "            if not features:\n",
    "                break\n",
    "            \n",
    "            # Use 'pd' which we imported in Block 1\n",
    "            df_batch = pd.DataFrame([f['properties'] for f in features])\n",
    "            \n",
    "            # Clean the year but keep original columns\n",
    "            if 'year' in df_batch.columns:\n",
    "                df_batch['year_clean'] = df_batch['year'].astype(str).str[:4]\n",
    "            \n",
    "            # Save batch to the SQL table\n",
    "            df_batch.to_sql('FullMineralData', conn, if_exists='append', index=False)\n",
    "            \n",
    "            offset += len(features)\n",
    "            print(f\"‚úÖ Secured {offset} / {total_expected} rows...\")\n",
    "            \n",
    "            time.sleep(0.5) \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error at row {offset}: {e}\")\n",
    "            break\n",
    "\n",
    "    # Add the \"Speed Boost\" indexes\n",
    "    print(\"‚ö° Creating high-speed indexes...\")\n",
    "    conn.execute(\"CREATE INDEX idx_mineral_group ON FullMineralData(erml_group);\")\n",
    "    conn.execute(\"CREATE INDEX idx_year_clean ON FullMineralData(year_clean);\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(f\"üéä FINISHED! Your master tool is ready.\")\n",
    "\n",
    "# Run the function\n",
    "build_master_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "968fc67a-617c-41e4-b674-5f97aabd1fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ† Adding 'shape' column to table...\n",
      "üì• Fetching the final missing batch...\n",
      "‚úÖ Success! Added the final 3480 rows.\n",
      "üè∑ Renaming table to 'BGS_Global'...\n",
      "üìä FINAL VERIFICATION: 408,480 rows secured in 'BGS_Global'.\n"
     ]
    }
   ],
   "source": [
    "# 1. Connect to your database\n",
    "conn = sqlite3.connect(\"BGS_Full_Archive_Master.db\")\n",
    "\n",
    "try:\n",
    "    # 2. Add the missing 'shape' column manually so SQLite is ready for it\n",
    "    print(\"üõ† Adding 'shape' column to table...\")\n",
    "    conn.execute(\"ALTER TABLE FullMineralData ADD COLUMN shape TEXT;\")\n",
    "    conn.commit()\n",
    "except sqlite3.OperationalError:\n",
    "    print(\"‚ÑπÔ∏è Column 'shape' already exists, moving to data retrieval.\")\n",
    "\n",
    "# 3. Fetch the final missing batch (from row 405,000 to the end)\n",
    "print(\"üì• Fetching the final missing batch...\")\n",
    "base_url = \"https://ogcapi.bgs.ac.uk/collections/world-mineral-statistics/items\"\n",
    "params = {'f': 'json', 'limit': 5000, 'offset': 405000}\n",
    "response = requests.get(base_url, params=params, timeout=60)\n",
    "data = response.json()\n",
    "features = data.get('features', [])\n",
    "\n",
    "if features:\n",
    "    # Convert to DataFrame\n",
    "    df_final = pd.DataFrame([f['properties'] for f in features])\n",
    "    \n",
    "    # Add our custom year_clean column\n",
    "    if 'year' in df_final.columns:\n",
    "        df_final['year_clean'] = df_final['year'].astype(str).str[:4]\n",
    "    \n",
    "    # Save the final batch\n",
    "    df_final.to_sql('FullMineralData', conn, if_exists='append', index=False)\n",
    "    print(f\"‚úÖ Success! Added the final {len(features)} rows.\")\n",
    "\n",
    "# 4. Final Cleanup: Rename to the professional name\n",
    "print(\"üè∑ Renaming table to 'BGS_Global'...\")\n",
    "conn.execute(\"ALTER TABLE FullMineralData RENAME TO BGS_Global;\")\n",
    "\n",
    "# 5. Final Row Count Check\n",
    "cursor = conn.execute(\"SELECT COUNT(*) FROM BGS_Global;\")\n",
    "final_count = cursor.fetchone()[0]\n",
    "print(f\"üìä FINAL VERIFICATION: {final_count:,} rows secured in 'BGS_Global'.\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d2ca61-56c1-41c2-a086-6cdc131f1ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Connection closed.\n",
      "‚úÖ Success! Renamed to: World_Mineral_Archive.db\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "# 1. Manually trigger garbage collection to clear stray objects\n",
    "gc.collect()\n",
    "\n",
    "# 2. Try to close the specific variables if they exist in this session\n",
    "try:\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        print(\"üîå Connection closed.\")\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# 3. Now try the rename again\n",
    "old_name = \"BGS_Full_Archive_Master.db\"\n",
    "new_name = \"World_Mineral_Archive.db\"\n",
    "\n",
    "if os.path.exists(old_name):\n",
    "    try:\n",
    "        os.rename(old_name, new_name)\n",
    "        print(f\"‚úÖ Success! Renamed to: {new_name}\")\n",
    "    except PermissionError:\n",
    "        print(\"‚ùå Still locked! Try clicking 'Kernel' -> 'Restart' in your notebook menu.\")\n",
    "else:\n",
    "    print(\"üìÇ File already renamed or not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e31a7e6-6629-43c7-b879-64ce42f3dfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Auditing BGS API for records beyond 408,480...\n",
      "üéØ MATCH! The API is empty at offset 408,480.\n",
      "‚úÖ Your local database is 100% synchronized with the British Geological Survey.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "\n",
    "# Define the next starting point after your current data\n",
    "next_offset = 408480 \n",
    "api_url = \"https://ogcapi.bgs.ac.uk/collections/world-mineral-statistics/items\"\n",
    "\n",
    "print(f\"üîç Auditing BGS API for records beyond {next_offset:,}...\")\n",
    "\n",
    "try:\n",
    "    # Request just 1 row at the next offset\n",
    "    response = requests.get(api_url, params={'f': 'json', 'limit': 1, 'offset': next_offset}, timeout=30)\n",
    "    data = response.json()\n",
    "    extra_features = data.get('features', [])\n",
    "\n",
    "    if not extra_features:\n",
    "        print(f\"üéØ MATCH! The API is empty at offset {next_offset:,}.\")\n",
    "        print(f\"‚úÖ Your local database is 100% synchronized with the British Geological Survey.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è DISCREPANCY! The API found a record at {next_offset:,}.\")\n",
    "        print(\"This means the BGS database grew while we were harvesting. Run a final mini-harvest!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Verification failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
